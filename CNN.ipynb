{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from utils.preprocess import getData\n",
    "from utils.validate import validate\n",
    "from networks.cnn import BasicCNN\n",
    "from networks.cnn import OptimizedCNN\n",
    "from networks.cnn import OptimizedCNNV2\n",
    "from networks.cnn import DeepCNN\n",
    "from networks.cnn import VariableFiltersCNN\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.test_accuracy import test\n",
    "from utils.test_accuracy import compute_test_outputs\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Load, Preprocess Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test, mapToOriginal = getData(lib='torch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: torch.Size([1728, 22, 250, 1])\n",
      "Valid data shape: torch.Size([423, 22, 250, 1])\n",
      "Test data shape: torch.Size([1772, 22, 250, 1])\n",
      "Training target shape: torch.Size([1728, 4])\n",
      "Valid target shape: torch.Size([423, 4])\n",
      "Test target shape: torch.Size([1772, 4])\n"
     ]
    }
   ],
   "source": [
    "print('Training data shape: {}'.format(X_train.shape))\n",
    "print('Valid data shape: {}'.format(X_valid.shape))\n",
    "print('Test data shape: {}'.format(X_test.shape))\n",
    "\n",
    "print('Training target shape: {}'.format(y_train.shape))\n",
    "print('Valid target shape: {}'.format(y_valid.shape))\n",
    "print('Test target shape: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Dataset and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "trainset = torch.utils.data.TensorDataset(X_train,y_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "# Shuffle is set to false for validation and test sets since no training is done on them, all we do is evaluate.\n",
    "valset =  torch.utils.data.TensorDataset(X_valid, y_valid)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=0)\n",
    "\n",
    "testset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                          shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicCNN(\n",
      "  (conv1): Conv2d(22, 25, kernel_size=(10, 1), stride=(1, 1), padding=same)\n",
      "  (pool1): MaxPool2d(kernel_size=(3, 1), stride=1, padding=(1, 0), dilation=1, ceil_mode=False)\n",
      "  (batchnorm1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout1): Dropout(p=0.4, inplace=False)\n",
      "  (conv2): Conv2d(25, 50, kernel_size=(10, 1), stride=(1, 1), padding=same)\n",
      "  (pool2): MaxPool2d(kernel_size=(3, 1), stride=1, padding=(1, 0), dilation=1, ceil_mode=False)\n",
      "  (batchnorm2): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout2): Dropout(p=0.4, inplace=False)\n",
      "  (conv3): Conv2d(50, 100, kernel_size=(10, 1), stride=(1, 1), padding=same)\n",
      "  (pool3): MaxPool2d(kernel_size=(3, 1), stride=1, padding=(1, 0), dilation=1, ceil_mode=False)\n",
      "  (batchnorm3): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout3): Dropout(p=0.4, inplace=False)\n",
      "  (conv4): Conv2d(100, 200, kernel_size=(10, 1), stride=(1, 1), padding=same)\n",
      "  (pool4): MaxPool2d(kernel_size=(3, 1), stride=1, padding=(1, 0), dilation=1, ceil_mode=False)\n",
      "  (batchnorm4): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout4): Dropout(p=0.4, inplace=False)\n",
      "  (affine): Linear(in_features=50000, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network\n",
    "network = BasicCNN()\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siddharthladha/opt/anaconda3/envs/finalProject/lib/python3.9/site-packages/torch/nn/modules/conv.py:442: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ../aten/src/ATen/native/Convolution.cpp:647.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t -- Train Loss: 3.2646478523901843 | Train Accuracy: 42.47126436781609\n",
      "\t -- Val Loss: 2.778337443868319 | Val Accuracy: 47.4\n",
      "Epoch: 1\n",
      "\t -- Train Loss: 2.6728703833501273 | Train Accuracy: 56.867816091954026\n",
      "\t -- Val Loss: 1.7206367899974186 | Val Accuracy: 62.6\n",
      "Epoch: 2\n",
      "\t -- Train Loss: 1.8336009678490666 | Train Accuracy: 67.05459770114942\n",
      "\t -- Val Loss: 1.5905541256070137 | Val Accuracy: 66.0\n",
      "Epoch: 3\n",
      "\t -- Train Loss: 1.3209000076722661 | Train Accuracy: 73.72126436781609\n",
      "\t -- Val Loss: 1.4152166247367859 | Val Accuracy: 69.66666666666667\n",
      "Epoch: 4\n",
      "\t -- Train Loss: 0.9155816865076712 | Train Accuracy: 80.17241379310344\n",
      "\t -- Val Loss: 0.9820176747937998 | Val Accuracy: 78.0\n",
      "Epoch: 5\n",
      "\t -- Train Loss: 0.6672043010182337 | Train Accuracy: 83.47701149425288\n",
      "\t -- Val Loss: 0.7940009571611881 | Val Accuracy: 79.73333333333333\n",
      "Epoch: 6\n",
      "\t -- Train Loss: 0.5427009351209763 | Train Accuracy: 86.6235632183908\n",
      "\t -- Val Loss: 0.3672515243912737 | Val Accuracy: 88.8\n",
      "Epoch: 7\n",
      "\t -- Train Loss: 0.43244507799454784 | Train Accuracy: 88.36206896551724\n",
      "\t -- Val Loss: 0.4982106393824021 | Val Accuracy: 86.4\n",
      "Epoch: 8\n",
      "\t -- Train Loss: 0.32816122103174894 | Train Accuracy: 90.76149425287356\n",
      "\t -- Val Loss: 0.46165689763923484 | Val Accuracy: 87.2\n",
      "Epoch: 9\n",
      "\t -- Train Loss: 0.28240288233538285 | Train Accuracy: 91.63793103448276\n",
      "\t -- Val Loss: 0.5187592646107078 | Val Accuracy: 86.2\n",
      "Epoch: 10\n",
      "\t -- Train Loss: 0.22005971476709077 | Train Accuracy: 93.23275862068965\n",
      "\t -- Val Loss: 0.281579543525974 | Val Accuracy: 92.26666666666667\n",
      "Epoch: 11\n",
      "\t -- Train Loss: 0.19060137367234864 | Train Accuracy: 94.00862068965517\n",
      "\t -- Val Loss: 0.3356117137397329 | Val Accuracy: 91.66666666666667\n",
      "Epoch: 12\n",
      "\t -- Train Loss: 0.16903095487334313 | Train Accuracy: 95.05747126436782\n",
      "\t -- Val Loss: 0.28745704299459857 | Val Accuracy: 91.8\n",
      "Epoch: 13\n",
      "\t -- Train Loss: 0.1565982841741328 | Train Accuracy: 94.97126436781609\n",
      "\t -- Val Loss: 0.20150791915754476 | Val Accuracy: 93.86666666666666\n",
      "Epoch: 14\n",
      "\t -- Train Loss: 0.1316709002103964 | Train Accuracy: 95.67528735632185\n",
      "\t -- Val Loss: 0.11588963627582416 | Val Accuracy: 97.0\n",
      "Epoch: 15\n",
      "\t -- Train Loss: 0.11331336578320063 | Train Accuracy: 96.30747126436782\n",
      "\t -- Val Loss: 0.15602193627273664 | Val Accuracy: 95.93333333333334\n",
      "Epoch: 16\n",
      "\t -- Train Loss: 0.11588848456569495 | Train Accuracy: 96.22126436781609\n",
      "\t -- Val Loss: 0.1341211834611992 | Val Accuracy: 96.6\n",
      "Epoch: 17\n",
      "\t -- Train Loss: 0.0981991069643425 | Train Accuracy: 96.70977011494253\n",
      "\t -- Val Loss: 0.20762616458038488 | Val Accuracy: 95.26666666666667\n",
      "Epoch: 18\n",
      "\t -- Train Loss: 0.09124696907083239 | Train Accuracy: 97.11206896551724\n",
      "\t -- Val Loss: 0.16936830795990923 | Val Accuracy: 96.06666666666666\n",
      "Epoch: 19\n",
      "\t -- Train Loss: 0.09757980883736676 | Train Accuracy: 96.86781609195403\n",
      "\t -- Val Loss: 0.15910534219195446 | Val Accuracy: 96.53333333333333\n"
     ]
    }
   ],
   "source": [
    "# Select loss criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.001)\n",
    "\n",
    "# Setup learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "# Train the network\n",
    "num_epochs = 20\n",
    "\n",
    "# Store the loss\n",
    "stats = {\n",
    "    'train_accuracies': [],\n",
    "    'train_losses': [],\n",
    "    'val_accuracies': [],\n",
    "    'val_losses': []\n",
    "}\n",
    "\n",
    "for epoch in range(num_epochs): # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.float()\n",
    "        labels = labels.float()\n",
    "  \n",
    "        # forward pass\n",
    "        outputs = network(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "\n",
    "        # backward + optimize\n",
    "        loss.backward() # backward to get gradient values\n",
    "        \n",
    "        optimizer.step() # does the update\n",
    "    \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # accumulate loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Make prediction for batch\n",
    "        _, predicted = outputs.max(1)\n",
    "        \n",
    "        # Store accuracy for batch\n",
    "        # WE convert back from one-hot to integer for checking accuracy\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(torch.argmax(labels, dim=1)).sum().item()\n",
    "        \n",
    "    # Store accuracy,loss for epoch\n",
    "    train_loss=running_loss/len(trainloader)\n",
    "    train_accuracy=100.*correct/total\n",
    "    \n",
    "    # At the end of each epoch, calculate validation accuracy\n",
    "    \n",
    "    # Set the network in eval mode since we're not training here\n",
    "    network.eval()\n",
    "    \n",
    "     # Turn gradient computation off\n",
    "    with torch.no_grad():\n",
    "        val_accuracy, val_loss = validate(network, valloader, criterion)\n",
    "    \n",
    "    # Set the network back in training mode\n",
    "    network.train()\n",
    "    \n",
    "    stats['train_accuracies'].append(train_accuracy)\n",
    "    stats['train_losses'].append(train_loss)\n",
    "    stats['val_accuracies'].append(val_accuracy)\n",
    "    stats['val_losses'].append(val_loss)\n",
    "    \n",
    "    \n",
    "    # Display results\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t -- Train Loss: {train_loss} | Train Accuracy: {train_accuracy}')\n",
    "    print(f'\\t -- Val Loss: {val_loss} | Val Accuracy: {val_accuracy}')\n",
    "    \n",
    "    # At the end of each epoch, schedule the learning rate decay\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.arange(num_epochs), stats['train_losses'], label='Training')\n",
    "plt.plot(np.arange(num_epochs), stats['val_losses'], label='Validation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(num_epochs), stats['train_accuracies'], label='Training')\n",
    "plt.plot(np.arange(num_epochs), stats['val_accuracies'], label='Validation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:79] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 443 test examples: 57.78781038374717 %\n"
     ]
    }
   ],
   "source": [
    "# Set the network in eval mode since we're not training here\n",
    "\n",
    "network.eval()\n",
    "outputs = None\n",
    "\n",
    " # Turn gradient computation off\n",
    "with torch.no_grad():\n",
    "    outputs = compute_test_outputs(network,testloader,y_test)\n",
    "    \n",
    "# Set the network back in training mode\n",
    "network.train()\n",
    "    \n",
    "    \n",
    "test_accuracy = test(outputs, mapToOriginal['y_test'])\n",
    "\n",
    "num_examples = mapToOriginal['y_test'].size\n",
    "\n",
    "\n",
    "print(f'Accuracy of the network on the {num_examples} test examples: {test_accuracy} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model for inference or further training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"saved-models/basicCNN2.pth\"\n",
    "state = {\n",
    "    'epoch': 5,\n",
    "    'state_dict': network.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "}\n",
    "torch.save(state, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing the model\n",
    "\n",
    "Now, let us try to optimize the model by varying the configuration of the layers, and using hyperparameter tuning to determine the best filter size, among other hyper paramaters\n",
    "\n",
    "From lectures, we have learnt that it is often useful to have multiple convolutional layers before a pooling layer to add complexity to our model.\n",
    "\n",
    "In addition, it is also advisable to put the batch-normalization layer immediately after the convolutional layer. (from lecture).\n",
    "\n",
    "Let us try these ideas below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OptimizedCNN(\n",
      "  (conv1): Conv2d(22, 25, kernel_size=(10, 1), stride=(1, 1), padding=same)\n",
      "  (batchnorm1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout1): Dropout(p=0.4, inplace=False)\n",
      "  (conv2): Conv2d(25, 50, kernel_size=(10, 1), stride=(1, 1), padding=same)\n",
      "  (batchnorm2): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout2): Dropout(p=0.4, inplace=False)\n",
      "  (pool1): MaxPool2d(kernel_size=(3, 1), stride=1, padding=(1, 0), dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(50, 100, kernel_size=(10, 1), stride=(1, 1), padding=same)\n",
      "  (batchnorm3): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout3): Dropout(p=0.4, inplace=False)\n",
      "  (conv4): Conv2d(100, 200, kernel_size=(10, 1), stride=(1, 1), padding=same)\n",
      "  (batchnorm4): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout4): Dropout(p=0.4, inplace=False)\n",
      "  (pool2): MaxPool2d(kernel_size=(3, 1), stride=1, padding=(1, 0), dilation=1, ceil_mode=False)\n",
      "  (affine): Linear(in_features=50000, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network\n",
    "network = OptimizedCNN()\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t -- Train Loss: 7.163239629990464 | Train Accuracy: 31.882183908045977\n",
      "\t -- Val Loss: 3.117256780465444 | Val Accuracy: 32.53333333333333\n",
      "Epoch: 1\n",
      "\t -- Train Loss: 5.40870305266949 | Train Accuracy: 39.798850574712645\n",
      "\t -- Val Loss: 27.874557971954346 | Val Accuracy: 28.666666666666668\n",
      "Epoch: 2\n",
      "\t -- Train Loss: 4.09515522051295 | Train Accuracy: 43.9080459770115\n",
      "\t -- Val Loss: 43.28024927775065 | Val Accuracy: 30.733333333333334\n",
      "Epoch: 3\n",
      "\t -- Train Loss: 2.933387707132812 | Train Accuracy: 47.701149425287355\n",
      "\t -- Val Loss: 12341.8271484375 | Val Accuracy: 24.466666666666665\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m  \u001b[38;5;66;03m# Turn gradient computation off\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 67\u001b[0m     val_accuracy, val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Set the network back in training mode\u001b[39;00m\n\u001b[1;32m     70\u001b[0m network\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/Desktop/ECE C147/Project/project-code/utils/validate.py:18\u001b[0m, in \u001b[0;36mvalidate\u001b[0;34m(network, valloader, criterion)\u001b[0m\n\u001b[1;32m     15\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     16\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m---> 18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     20\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/finalProject/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/ECE C147/Project/project-code/networks/cnn.py:137\u001b[0m, in \u001b[0;36mOptimizedCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# [conv-batchnorm-relu-dropout-conv-batchnorm-relu-dropout]\u001b[39;00m\n\u001b[1;32m    136\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout3(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatchnorm3(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x))))\n\u001b[0;32m--> 137\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout4(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatchnorm4(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)))\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# pool\u001b[39;00m\n\u001b[1;32m    141\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool2(x)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/finalProject/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/finalProject/lib/python3.9/site-packages/torch/nn/modules/conv.py:446\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/finalProject/lib/python3.9/site-packages/torch/nn/modules/conv.py:442\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    440\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    441\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 442\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Select loss criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.001)\n",
    "\n",
    "# Setup learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "# Train the network\n",
    "num_epochs = 10\n",
    "\n",
    "# Store the loss\n",
    "stats = {\n",
    "    'train_accuracies': [],\n",
    "    'train_losses': [],\n",
    "    'val_accuracies': [],\n",
    "    'val_losses': []\n",
    "}\n",
    "\n",
    "for epoch in range(num_epochs): # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.float()\n",
    "        labels = labels.float()\n",
    "  \n",
    "        # forward pass\n",
    "        outputs = network(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "\n",
    "        # backward + optimize\n",
    "        loss.backward() # backward to get gradient values\n",
    "        \n",
    "        optimizer.step() # does the update\n",
    "    \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # accumulate loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Make prediction for batch\n",
    "        _, predicted = outputs.max(1)\n",
    "        \n",
    "        # Store accuracy for batch\n",
    "        # WE convert back from one-hot to integer for checking accuracy\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(torch.argmax(labels, dim=1)).sum().item()\n",
    "        \n",
    "    # Store accuracy,loss for epoch\n",
    "    train_loss=running_loss/len(trainloader)\n",
    "    train_accuracy=100.*correct/total\n",
    "    \n",
    "    # At the end of each epoch, calculate validation accuracy\n",
    "    \n",
    "    # Set the network in eval mode since we're not training here\n",
    "    network.eval()\n",
    "    \n",
    "     # Turn gradient computation off\n",
    "    with torch.no_grad():\n",
    "        val_accuracy, val_loss = validate(network, valloader, criterion)\n",
    "    \n",
    "    # Set the network back in training mode\n",
    "    network.train()\n",
    "    \n",
    "    stats['train_accuracies'].append(train_accuracy)\n",
    "    stats['train_losses'].append(train_loss)\n",
    "    stats['val_accuracies'].append(val_accuracy)\n",
    "    stats['val_losses'].append(val_loss)\n",
    "    \n",
    "    \n",
    "    # Display results\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t -- Train Loss: {train_loss} | Train Accuracy: {train_accuracy}')\n",
    "    print(f'\\t -- Val Loss: {val_loss} | Val Accuracy: {val_accuracy}')\n",
    "    \n",
    "    # At the end of each epoch, schedule the learning rate decay\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:79] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 443 test examples: 40.85778781038375 %\n"
     ]
    }
   ],
   "source": [
    "network.eval()\n",
    "outputs = None\n",
    "\n",
    " # Turn gradient computation off\n",
    "with torch.no_grad():\n",
    "    outputs = compute_test_outputs(network,testloader,y_test)\n",
    "    \n",
    "# Set the network back in training mode\n",
    "network.train()\n",
    "    \n",
    "    \n",
    "test_accuracy = test(outputs, mapToOriginal['y_test'])\n",
    "\n",
    "num_examples = mapToOriginal['y_test'].size\n",
    "\n",
    "\n",
    "print(f'Accuracy of the network on the {num_examples} test examples: {test_accuracy} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing Again\n",
    "\n",
    "However, after testing such an architecture, we find that it performs worse than the BasicCNN above.\n",
    "\n",
    "In that case, we turn to a new idea: Using the same BasicCNN architecture, but changing varying filter sizes and numbers, along with dropout probabilities as shown below:\n",
    "\n",
    "Since we are performing much worse on the test set than the train and validation set, we can assume that our model needs to generalize to unseen data better. Thus, we should explore a more aggressive dropout value. The above model does this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OptimizedCNNV2(\n",
      "  (conv1): Conv2d(22, 25, kernel_size=(10, 1), stride=(1, 1), padding=same)\n",
      "  (pool1): MaxPool2d(kernel_size=(3, 1), stride=1, padding=(1, 0), dilation=1, ceil_mode=False)\n",
      "  (batchnorm1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout1): Dropout(p=0.6, inplace=False)\n",
      "  (conv2): Conv2d(25, 50, kernel_size=(10, 1), stride=(1, 1), padding=same)\n",
      "  (pool2): MaxPool2d(kernel_size=(3, 1), stride=1, padding=(1, 0), dilation=1, ceil_mode=False)\n",
      "  (batchnorm2): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout2): Dropout(p=0.6, inplace=False)\n",
      "  (conv3): Conv2d(50, 100, kernel_size=(10, 1), stride=(1, 1), padding=same)\n",
      "  (pool3): MaxPool2d(kernel_size=(3, 1), stride=1, padding=(1, 0), dilation=1, ceil_mode=False)\n",
      "  (batchnorm3): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout3): Dropout(p=0.6, inplace=False)\n",
      "  (conv4): Conv2d(100, 200, kernel_size=(10, 1), stride=(1, 1), padding=same)\n",
      "  (pool4): MaxPool2d(kernel_size=(3, 1), stride=1, padding=(1, 0), dilation=1, ceil_mode=False)\n",
      "  (batchnorm4): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout4): Dropout(p=0.6, inplace=False)\n",
      "  (affine): Linear(in_features=50000, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network\n",
    "network = OptimizedCNNV2(dropout=0.6)\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t -- Train Loss: 3.3448479788019023 | Train Accuracy: 36.5948275862069\n",
      "\t -- Val Loss: 3.936804632345835 | Val Accuracy: 33.266666666666666\n",
      "Epoch: 1\n",
      "\t -- Train Loss: 3.791455459157261 | Train Accuracy: 44.89942528735632\n",
      "\t -- Val Loss: 3.4451233943303428 | Val Accuracy: 42.333333333333336\n",
      "Epoch: 2\n",
      "\t -- Train Loss: 3.117615513845321 | Train Accuracy: 51.910919540229884\n",
      "\t -- Val Loss: 3.5258830785751343 | Val Accuracy: 48.13333333333333\n",
      "Epoch: 3\n",
      "\t -- Train Loss: 2.824068847052548 | Train Accuracy: 55.40229885057471\n",
      "\t -- Val Loss: 2.5542559574047723 | Val Accuracy: 52.6\n",
      "Epoch: 4\n",
      "\t -- Train Loss: 2.255259522604286 | Train Accuracy: 61.30747126436781\n",
      "\t -- Val Loss: 1.7741254170735676 | Val Accuracy: 60.4\n",
      "Epoch: 5\n",
      "\t -- Train Loss: 2.0331569735063324 | Train Accuracy: 62.98850574712644\n",
      "\t -- Val Loss: 2.6911876996358237 | Val Accuracy: 52.86666666666667\n",
      "Epoch: 6\n",
      "\t -- Train Loss: 1.8464201918435752 | Train Accuracy: 66.02011494252874\n",
      "\t -- Val Loss: 1.7625255386034648 | Val Accuracy: 56.53333333333333\n",
      "Epoch: 7\n",
      "\t -- Train Loss: 1.6757942930274052 | Train Accuracy: 67.44252873563218\n",
      "\t -- Val Loss: 2.353191708525022 | Val Accuracy: 52.0\n",
      "Epoch: 8\n",
      "\t -- Train Loss: 1.4333283906682917 | Train Accuracy: 70.28735632183908\n",
      "\t -- Val Loss: 2.7038501600424447 | Val Accuracy: 54.733333333333334\n",
      "Epoch: 9\n",
      "\t -- Train Loss: 1.379156284376022 | Train Accuracy: 71.25\n",
      "\t -- Val Loss: 2.122082238396009 | Val Accuracy: 57.06666666666667\n"
     ]
    }
   ],
   "source": [
    "# Select loss criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.001)\n",
    "\n",
    "# Setup learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "# Train the network\n",
    "num_epochs = 10\n",
    "\n",
    "# Store the loss\n",
    "stats = {\n",
    "    'train_accuracies': [],\n",
    "    'train_losses': [],\n",
    "    'val_accuracies': [],\n",
    "    'val_losses': []\n",
    "}\n",
    "\n",
    "for epoch in range(num_epochs): # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.float()\n",
    "        labels = labels.float()\n",
    "  \n",
    "        # forward pass\n",
    "        outputs = network(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "\n",
    "        # backward + optimize\n",
    "        loss.backward() # backward to get gradient values\n",
    "        \n",
    "        optimizer.step() # does the update\n",
    "    \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # accumulate loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Make prediction for batch\n",
    "        _, predicted = outputs.max(1)\n",
    "        \n",
    "        # Store accuracy for batch\n",
    "        # WE convert back from one-hot to integer for checking accuracy\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(torch.argmax(labels, dim=1)).sum().item()\n",
    "        \n",
    "    # Store accuracy,loss for epoch\n",
    "    train_loss=running_loss/len(trainloader)\n",
    "    train_accuracy=100.*correct/total\n",
    "    \n",
    "    # At the end of each epoch, calculate validation accuracy\n",
    "    \n",
    "    # Set the network in eval mode since we're not training here\n",
    "    network.eval()\n",
    "    \n",
    "     # Turn gradient computation off\n",
    "    with torch.no_grad():\n",
    "        val_accuracy, val_loss = validate(network, valloader, criterion)\n",
    "    \n",
    "    # Set the network back in training mode\n",
    "    network.train()\n",
    "    \n",
    "    stats['train_accuracies'].append(train_accuracy)\n",
    "    stats['train_losses'].append(train_loss)\n",
    "    stats['val_accuracies'].append(val_accuracy)\n",
    "    stats['val_losses'].append(val_loss)\n",
    "    \n",
    "    \n",
    "    # Display results\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t -- Train Loss: {train_loss} | Train Accuracy: {train_accuracy}')\n",
    "    print(f'\\t -- Val Loss: {val_loss} | Val Accuracy: {val_accuracy}')\n",
    "    \n",
    "    # At the end of each epoch, schedule the learning rate decay\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 443 test examples: 25.056433408577877 %\n"
     ]
    }
   ],
   "source": [
    "network.eval()\n",
    "outputs = None\n",
    "\n",
    " # Turn gradient computation off\n",
    "with torch.no_grad():\n",
    "    outputs = compute_test_outputs(network,testloader,y_test)\n",
    "    \n",
    "# Set the network back in training mode\n",
    "network.train()\n",
    "    \n",
    "    \n",
    "test_accuracy = test(outputs, mapToOriginal['y_test'])\n",
    "\n",
    "num_examples = mapToOriginal['y_test'].size\n",
    "\n",
    "\n",
    "print(f'Accuracy of the network on the {num_examples} test examples: {test_accuracy} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the aggressive dropout value does not seem to work. Let us now try changing the convolutional filter size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OptimizedCNNV2(\n",
      "  (conv1): Conv2d(22, 25, kernel_size=(20, 1), stride=(1, 1), padding=same)\n",
      "  (pool1): MaxPool2d(kernel_size=(3, 1), stride=1, padding=(1, 0), dilation=1, ceil_mode=False)\n",
      "  (batchnorm1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout1): Dropout(p=0.4, inplace=False)\n",
      "  (conv2): Conv2d(25, 50, kernel_size=(20, 1), stride=(1, 1), padding=same)\n",
      "  (pool2): MaxPool2d(kernel_size=(3, 1), stride=1, padding=(1, 0), dilation=1, ceil_mode=False)\n",
      "  (batchnorm2): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout2): Dropout(p=0.4, inplace=False)\n",
      "  (conv3): Conv2d(50, 100, kernel_size=(20, 1), stride=(1, 1), padding=same)\n",
      "  (pool3): MaxPool2d(kernel_size=(3, 1), stride=1, padding=(1, 0), dilation=1, ceil_mode=False)\n",
      "  (batchnorm3): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout3): Dropout(p=0.4, inplace=False)\n",
      "  (conv4): Conv2d(100, 200, kernel_size=(20, 1), stride=(1, 1), padding=same)\n",
      "  (pool4): MaxPool2d(kernel_size=(3, 1), stride=1, padding=(1, 0), dilation=1, ceil_mode=False)\n",
      "  (batchnorm4): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout4): Dropout(p=0.4, inplace=False)\n",
      "  (affine): Linear(in_features=50000, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "network = OptimizedCNNV2(dropout=0.4, filter_size = (20,1))\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t -- Train Loss: 3.7248429409954524 | Train Accuracy: 37.42816091954023\n",
      "\t -- Val Loss: 3.0248947739601135 | Val Accuracy: 40.666666666666664\n",
      "Epoch: 1\n",
      "\t -- Train Loss: 2.826133613192707 | Train Accuracy: 50.67528735632184\n",
      "\t -- Val Loss: 2.754539499680201 | Val Accuracy: 49.4\n",
      "Epoch: 2\n",
      "\t -- Train Loss: 2.000901311909387 | Train Accuracy: 60.79022988505747\n",
      "\t -- Val Loss: 1.693855106830597 | Val Accuracy: 62.46666666666667\n",
      "Epoch: 3\n",
      "\t -- Train Loss: 1.3590182645605244 | Train Accuracy: 69.55459770114942\n",
      "\t -- Val Loss: 1.1361853207151096 | Val Accuracy: 70.73333333333333\n",
      "Epoch: 4\n",
      "\t -- Train Loss: 1.0640239805803386 | Train Accuracy: 75.47413793103448\n",
      "\t -- Val Loss: 1.1719834382335346 | Val Accuracy: 70.53333333333333\n",
      "Epoch: 5\n",
      "\t -- Train Loss: 0.7456813836043034 | Train Accuracy: 81.02011494252874\n",
      "\t -- Val Loss: 0.6136873755604029 | Val Accuracy: 82.73333333333333\n",
      "Epoch: 6\n",
      "\t -- Train Loss: 0.5266175070487031 | Train Accuracy: 84.94252873563218\n",
      "\t -- Val Loss: 0.4612935396532218 | Val Accuracy: 85.13333333333334\n",
      "Epoch: 7\n",
      "\t -- Train Loss: 0.4576059871037072 | Train Accuracy: 86.95402298850574\n",
      "\t -- Val Loss: 0.4385887148479621 | Val Accuracy: 86.93333333333334\n",
      "Epoch: 8\n",
      "\t -- Train Loss: 0.35014931420120626 | Train Accuracy: 89.39655172413794\n",
      "\t -- Val Loss: 0.2704994510859251 | Val Accuracy: 92.13333333333334\n",
      "Epoch: 9\n",
      "\t -- Train Loss: 0.2447361615101952 | Train Accuracy: 92.5\n",
      "\t -- Val Loss: 0.19918819734205803 | Val Accuracy: 93.4\n"
     ]
    }
   ],
   "source": [
    "# Select loss criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.001)\n",
    "\n",
    "# Setup learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "# Train the network\n",
    "num_epochs = 10\n",
    "\n",
    "# Store the loss\n",
    "stats = {\n",
    "    'train_accuracies': [],\n",
    "    'train_losses': [],\n",
    "    'val_accuracies': [],\n",
    "    'val_losses': []\n",
    "}\n",
    "\n",
    "for epoch in range(num_epochs): # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.float()\n",
    "        labels = labels.float()\n",
    "  \n",
    "        # forward pass\n",
    "        outputs = network(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "\n",
    "        # backward + optimize\n",
    "        loss.backward() # backward to get gradient values\n",
    "        \n",
    "        optimizer.step() # does the update\n",
    "    \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # accumulate loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Make prediction for batch\n",
    "        _, predicted = outputs.max(1)\n",
    "        \n",
    "        # Store accuracy for batch\n",
    "        # WE convert back from one-hot to integer for checking accuracy\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(torch.argmax(labels, dim=1)).sum().item()\n",
    "        \n",
    "    # Store accuracy,loss for epoch\n",
    "    train_loss=running_loss/len(trainloader)\n",
    "    train_accuracy=100.*correct/total\n",
    "    \n",
    "    # At the end of each epoch, calculate validation accuracy\n",
    "    \n",
    "    # Set the network in eval mode since we're not training here\n",
    "    network.eval()\n",
    "    \n",
    "     # Turn gradient computation off\n",
    "    with torch.no_grad():\n",
    "        val_accuracy, val_loss = validate(network, valloader, criterion)\n",
    "    \n",
    "    # Set the network back in training mode\n",
    "    network.train()\n",
    "    \n",
    "    stats['train_accuracies'].append(train_accuracy)\n",
    "    stats['train_losses'].append(train_loss)\n",
    "    stats['val_accuracies'].append(val_accuracy)\n",
    "    stats['val_losses'].append(val_loss)\n",
    "    \n",
    "    \n",
    "    # Display results\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t -- Train Loss: {train_loss} | Train Accuracy: {train_accuracy}')\n",
    "    print(f'\\t -- Val Loss: {val_loss} | Val Accuracy: {val_accuracy}')\n",
    "    \n",
    "    # At the end of each epoch, schedule the learning rate decay\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 443 test examples: 54.176072234762984 %\n"
     ]
    }
   ],
   "source": [
    "network.eval()\n",
    "outputs = None\n",
    "\n",
    " # Turn gradient computation off\n",
    "with torch.no_grad():\n",
    "    outputs = compute_test_outputs(network,testloader,y_test)\n",
    "    \n",
    "# Set the network back in training mode\n",
    "network.train()\n",
    "    \n",
    "    \n",
    "test_accuracy = test(outputs, mapToOriginal['y_test'])\n",
    "\n",
    "num_examples = mapToOriginal['y_test'].size\n",
    "\n",
    "\n",
    "print(f'Accuracy of the network on the {num_examples} test examples: {test_accuracy} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network performs about as well as our initial basic network. Let's now try decreasing the convolutional filter size, and increasing the depth of our network. (to maintain the same receptive field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepCNN(\n",
      "  (conv1): Conv2d(22, 25, kernel_size=(5, 1), stride=(1, 1), padding=same)\n",
      "  (pool1): MaxPool2d(kernel_size=(3, 1), stride=1, padding=(1, 0), dilation=1, ceil_mode=False)\n",
      "  (batchnorm1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout1): Dropout(p=0.4, inplace=False)\n",
      "  (conv2): Conv2d(25, 50, kernel_size=(5, 1), stride=(1, 1), padding=same)\n",
      "  (pool2): MaxPool2d(kernel_size=(3, 1), stride=1, padding=(1, 0), dilation=1, ceil_mode=False)\n",
      "  (batchnorm2): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout2): Dropout(p=0.4, inplace=False)\n",
      "  (conv3): Conv2d(50, 100, kernel_size=(5, 1), stride=(1, 1), padding=same)\n",
      "  (pool3): MaxPool2d(kernel_size=(3, 1), stride=1, padding=(1, 0), dilation=1, ceil_mode=False)\n",
      "  (batchnorm3): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout3): Dropout(p=0.4, inplace=False)\n",
      "  (conv4): Conv2d(100, 200, kernel_size=(5, 1), stride=(1, 1), padding=same)\n",
      "  (pool4): MaxPool2d(kernel_size=(3, 1), stride=1, padding=(1, 0), dilation=1, ceil_mode=False)\n",
      "  (batchnorm4): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout4): Dropout(p=0.4, inplace=False)\n",
      "  (conv5): Conv2d(200, 150, kernel_size=(5, 1), stride=(1, 1), padding=same)\n",
      "  (pool5): MaxPool2d(kernel_size=(3, 1), stride=1, padding=(1, 0), dilation=1, ceil_mode=False)\n",
      "  (batchnorm5): BatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout5): Dropout(p=0.4, inplace=False)\n",
      "  (conv6): Conv2d(150, 50, kernel_size=(5, 1), stride=(1, 1), padding=same)\n",
      "  (pool6): MaxPool2d(kernel_size=(3, 1), stride=1, padding=(1, 0), dilation=1, ceil_mode=False)\n",
      "  (batchnorm6): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout6): Dropout(p=0.4, inplace=False)\n",
      "  (affine): Linear(in_features=12500, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "network = DeepCNN(dropout=0.4, filter_size = (5,1))\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t -- Train Loss: 1.6492772058609428 | Train Accuracy: 40.60344827586207\n",
      "\t -- Val Loss: 1.2389489139119785 | Val Accuracy: 47.46666666666667\n",
      "Epoch: 1\n",
      "\t -- Train Loss: 1.3457449723821167 | Train Accuracy: 55.201149425287355\n",
      "\t -- Val Loss: 1.3005520502726238 | Val Accuracy: 49.4\n",
      "Epoch: 2\n",
      "\t -- Train Loss: 1.0438917328458313 | Train Accuracy: 63.160919540229884\n",
      "\t -- Val Loss: 1.1931135058403015 | Val Accuracy: 52.53333333333333\n",
      "Epoch: 3\n",
      "\t -- Train Loss: 0.8821134583665691 | Train Accuracy: 69.066091954023\n",
      "\t -- Val Loss: 0.8955751533309618 | Val Accuracy: 62.86666666666667\n",
      "Epoch: 4\n",
      "\t -- Train Loss: 0.699154916979851 | Train Accuracy: 74.18103448275862\n",
      "\t -- Val Loss: 0.7968036358555158 | Val Accuracy: 69.53333333333333\n",
      "Epoch: 5\n",
      "\t -- Train Loss: 0.5880448974053795 | Train Accuracy: 77.77298850574712\n",
      "\t -- Val Loss: 0.6987029674152533 | Val Accuracy: 73.2\n",
      "Epoch: 6\n",
      "\t -- Train Loss: 0.5064953859519521 | Train Accuracy: 81.16379310344827\n",
      "\t -- Val Loss: 0.6284670444826285 | Val Accuracy: 74.13333333333334\n",
      "Epoch: 7\n",
      "\t -- Train Loss: 0.4482110051113531 | Train Accuracy: 83.2183908045977\n",
      "\t -- Val Loss: 0.6232262750466665 | Val Accuracy: 74.73333333333333\n",
      "Epoch: 8\n",
      "\t -- Train Loss: 0.39188598834593363 | Train Accuracy: 85.1580459770115\n",
      "\t -- Val Loss: 0.4671938878794511 | Val Accuracy: 81.46666666666667\n",
      "Epoch: 9\n",
      "\t -- Train Loss: 0.36729744814951487 | Train Accuracy: 86.12068965517241\n",
      "\t -- Val Loss: 0.5277232403556505 | Val Accuracy: 79.86666666666666\n"
     ]
    }
   ],
   "source": [
    "# Select loss criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.001)\n",
    "\n",
    "# Setup learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "# Train the network\n",
    "num_epochs = 10\n",
    "\n",
    "# Store the loss\n",
    "stats = {\n",
    "    'train_accuracies': [],\n",
    "    'train_losses': [],\n",
    "    'val_accuracies': [],\n",
    "    'val_losses': []\n",
    "}\n",
    "\n",
    "for epoch in range(num_epochs): # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.float()\n",
    "        labels = labels.float()\n",
    "  \n",
    "        # forward pass\n",
    "        outputs = network(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "\n",
    "        # backward + optimize\n",
    "        loss.backward() # backward to get gradient values\n",
    "        \n",
    "        optimizer.step() # does the update\n",
    "    \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # accumulate loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Make prediction for batch\n",
    "        _, predicted = outputs.max(1)\n",
    "        \n",
    "        # Store accuracy for batch\n",
    "        # WE convert back from one-hot to integer for checking accuracy\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(torch.argmax(labels, dim=1)).sum().item()\n",
    "        \n",
    "    # Store accuracy,loss for epoch\n",
    "    train_loss=running_loss/len(trainloader)\n",
    "    train_accuracy=100.*correct/total\n",
    "    \n",
    "    # At the end of each epoch, calculate validation accuracy\n",
    "    \n",
    "    # Set the network in eval mode since we're not training here\n",
    "    network.eval()\n",
    "    \n",
    "     # Turn gradient computation off\n",
    "    with torch.no_grad():\n",
    "        val_accuracy, val_loss = validate(network, valloader, criterion)\n",
    "    \n",
    "    # Set the network back in training mode\n",
    "    network.train()\n",
    "    \n",
    "    stats['train_accuracies'].append(train_accuracy)\n",
    "    stats['train_losses'].append(train_loss)\n",
    "    stats['val_accuracies'].append(val_accuracy)\n",
    "    stats['val_losses'].append(val_loss)\n",
    "    \n",
    "    \n",
    "    # Display results\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t -- Train Loss: {train_loss} | Train Accuracy: {train_accuracy}')\n",
    "    print(f'\\t -- Val Loss: {val_loss} | Val Accuracy: {val_accuracy}')\n",
    "    \n",
    "    # At the end of each epoch, schedule the learning rate decay\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 443 test examples: 54.85327313769752 %\n"
     ]
    }
   ],
   "source": [
    "network.eval()\n",
    "outputs = None\n",
    "\n",
    " # Turn gradient computation off\n",
    "with torch.no_grad():\n",
    "    outputs = compute_test_outputs(network,testloader,y_test)\n",
    "    \n",
    "# Set the network back in training mode\n",
    "network.train()\n",
    "    \n",
    "    \n",
    "test_accuracy = test(outputs, mapToOriginal['y_test'])\n",
    "\n",
    "num_examples = mapToOriginal['y_test'].size\n",
    "\n",
    "\n",
    "print(f'Accuracy of the network on the {num_examples} test examples: {test_accuracy} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even this deeper CNN with smaller filter size does not perform better than the original Basic CNN. At this point, we concede that the Basic CNN architecture is the most suitable out of all the ones we tested, and we vary its number of filters and learning rate in an attempt to achieve even greater performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VariableFiltersCNN(\n",
      "  (conv1): Conv2d(22, 50, kernel_size=(10, 1), stride=(1, 1), padding=same)\n",
      "  (pool1): MaxPool2d(kernel_size=(3, 1), stride=1, padding=(1, 0), dilation=1, ceil_mode=False)\n",
      "  (batchnorm1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout1): Dropout(p=0.4, inplace=False)\n",
      "  (conv2): Conv2d(50, 100, kernel_size=(10, 1), stride=(1, 1), padding=same)\n",
      "  (pool2): MaxPool2d(kernel_size=(3, 1), stride=1, padding=(1, 0), dilation=1, ceil_mode=False)\n",
      "  (batchnorm2): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout2): Dropout(p=0.4, inplace=False)\n",
      "  (conv3): Conv2d(100, 200, kernel_size=(10, 1), stride=(1, 1), padding=same)\n",
      "  (pool3): MaxPool2d(kernel_size=(3, 1), stride=1, padding=(1, 0), dilation=1, ceil_mode=False)\n",
      "  (batchnorm3): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout3): Dropout(p=0.4, inplace=False)\n",
      "  (conv4): Conv2d(200, 250, kernel_size=(10, 1), stride=(1, 1), padding=same)\n",
      "  (pool4): MaxPool2d(kernel_size=(3, 1), stride=1, padding=(1, 0), dilation=1, ceil_mode=False)\n",
      "  (batchnorm4): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout4): Dropout(p=0.4, inplace=False)\n",
      "  (affine): Linear(in_features=62500, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "network = VariableFiltersCNN(filters=[50,100,200,250])\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t -- Train Loss: 3.0755797919877077 | Train Accuracy: 56.22126436781609\n",
      "\t -- Val Loss: 1.963074008623759 | Val Accuracy: 60.733333333333334\n",
      "Epoch: 1\n",
      "\t -- Train Loss: 2.8278079962511673 | Train Accuracy: 64.89942528735632\n",
      "\t -- Val Loss: 2.5242406179507575 | Val Accuracy: 68.2\n",
      "Epoch: 2\n",
      "\t -- Train Loss: 1.5940576332424758 | Train Accuracy: 76.19252873563218\n",
      "\t -- Val Loss: 1.1014363082746665 | Val Accuracy: 80.53333333333333\n",
      "Epoch: 3\n",
      "\t -- Train Loss: 0.8575210496099717 | Train Accuracy: 85.43103448275862\n",
      "\t -- Val Loss: 0.6017377520911396 | Val Accuracy: 86.4\n",
      "Epoch: 4\n",
      "\t -- Train Loss: 0.6627640864307728 | Train Accuracy: 87.61494252873563\n",
      "\t -- Val Loss: 0.7136821721990904 | Val Accuracy: 85.6\n",
      "Epoch: 5\n",
      "\t -- Train Loss: 0.37825643156714944 | Train Accuracy: 92.55747126436782\n",
      "\t -- Val Loss: 0.454383901009957 | Val Accuracy: 90.66666666666667\n",
      "Epoch: 6\n",
      "\t -- Train Loss: 0.22429401890605416 | Train Accuracy: 95.01436781609195\n",
      "\t -- Val Loss: 0.2379183537462571 | Val Accuracy: 93.86666666666666\n",
      "Epoch: 7\n",
      "\t -- Train Loss: 0.20316952373191646 | Train Accuracy: 95.11494252873563\n",
      "\t -- Val Loss: 0.23656040461113056 | Val Accuracy: 95.0\n",
      "Epoch: 8\n",
      "\t -- Train Loss: 0.16092561325485552 | Train Accuracy: 96.03448275862068\n",
      "\t -- Val Loss: 0.13598920693038963 | Val Accuracy: 97.33333333333333\n",
      "Epoch: 9\n",
      "\t -- Train Loss: 0.12532478374260297 | Train Accuracy: 96.68103448275862\n",
      "\t -- Val Loss: 0.16029670006476712 | Val Accuracy: 96.6\n"
     ]
    }
   ],
   "source": [
    "# Select loss criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.001)\n",
    "\n",
    "# Setup learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "# Train the network\n",
    "num_epochs = 10\n",
    "\n",
    "# Store the loss\n",
    "stats = {\n",
    "    'train_accuracies': [],\n",
    "    'train_losses': [],\n",
    "    'val_accuracies': [],\n",
    "    'val_losses': []\n",
    "}\n",
    "\n",
    "for epoch in range(num_epochs): # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.float()\n",
    "        labels = labels.float()\n",
    "  \n",
    "        # forward pass\n",
    "        outputs = network(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "\n",
    "        # backward + optimize\n",
    "        loss.backward() # backward to get gradient values\n",
    "        \n",
    "        optimizer.step() # does the update\n",
    "    \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # accumulate loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Make prediction for batch\n",
    "        _, predicted = outputs.max(1)\n",
    "        \n",
    "        # Store accuracy for batch\n",
    "        # WE convert back from one-hot to integer for checking accuracy\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(torch.argmax(labels, dim=1)).sum().item()\n",
    "        \n",
    "    # Store accuracy,loss for epoch\n",
    "    train_loss=running_loss/len(trainloader)\n",
    "    train_accuracy=100.*correct/total\n",
    "    \n",
    "    # At the end of each epoch, calculate validation accuracy\n",
    "    \n",
    "    # Set the network in eval mode since we're not training here\n",
    "    network.eval()\n",
    "    \n",
    "     # Turn gradient computation off\n",
    "    with torch.no_grad():\n",
    "        val_accuracy, val_loss = validate(network, valloader, criterion)\n",
    "    \n",
    "    # Set the network back in training mode\n",
    "    network.train()\n",
    "    \n",
    "    stats['train_accuracies'].append(train_accuracy)\n",
    "    stats['train_losses'].append(train_loss)\n",
    "    stats['val_accuracies'].append(val_accuracy)\n",
    "    stats['val_losses'].append(val_loss)\n",
    "    \n",
    "    \n",
    "    # Display results\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t -- Train Loss: {train_loss} | Train Accuracy: {train_accuracy}')\n",
    "    print(f'\\t -- Val Loss: {val_loss} | Val Accuracy: {val_accuracy}')\n",
    "    \n",
    "    # At the end of each epoch, schedule the learning rate decay\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 443 test examples: 59.14221218961625 %\n"
     ]
    }
   ],
   "source": [
    "# Set the network in eval mode since we're not training here\n",
    "\n",
    "network.eval()\n",
    "outputs = None\n",
    "\n",
    " # Turn gradient computation off\n",
    "with torch.no_grad():\n",
    "    outputs = compute_test_outputs(network,testloader,y_test)\n",
    "    \n",
    "# Set the network back in training mode\n",
    "network.train()\n",
    "    \n",
    "    \n",
    "test_accuracy = test(outputs, mapToOriginal['y_test'])\n",
    "\n",
    "num_examples = mapToOriginal['y_test'].size\n",
    "\n",
    "\n",
    "print(f'Accuracy of the network on the {num_examples} test examples: {test_accuracy} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the best network we've seen so far. It gets an accuracy slightly better than the next best CNN so far (BasicCNN), even though it trains for half the epochs. \n",
    "\n",
    "If we wanted, we could get much higher accuracy on this network by training for longer, but this would require a high amount of compute resources, and potentially a GPU. The large number of filters in each layer means training a batch takes a much larger amount of time than Basic CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.arange(num_epochs), stats['train_losses'], label='Training')\n",
    "plt.plot(np.arange(num_epochs), stats['val_losses'], label='Validation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(num_epochs), stats['train_accuracies'], label='Training')\n",
    "plt.plot(np.arange(num_epochs), stats['val_accuracies'], label='Validation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The best network for this task is the VariableFiltersCNN with filters=[50,100,200,250]. Thus, working with the BasicCNN and incresing the number of filters is the best way to get high accuracy on this dataset. We still need to train for a large number of epochs, though.\n",
    "\n",
    "However, there is still going to be a discrepancy between the accuracy on the train/validation and test sets. Increasing regularization through more aggressive dropout does not seem to help our network.\n",
    "\n",
    "In addition, experimenting with different learning rates might help our model, but since we use Batch Normalization and Xavier Initializations, our model should be more resistant to changes in learning rate.\n",
    "\n",
    "Finally, an idea to improve the test accuracy is to use more intensive preprocessing. A paper I found on preprocessing for EEG data, that was also used to preprocess data fro EEGNet, is here: \n",
    "\n",
    "https://www.frontiersin.org/articles/10.3389/fninf.2015.00016/full\n",
    "\n",
    "However, the code for the PREP pipeline is written is matlab, and given the time to complete the project, it was unfeasible to convert it to python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'network' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved-models/VariableFiltersCNN.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m state \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m9\u001b[39m,\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mnetwork\u001b[49m\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m: optimizer\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m      6\u001b[0m }\n\u001b[1;32m      7\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(state, path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'network' is not defined"
     ]
    }
   ],
   "source": [
    "path = \"saved-models/VariableFiltersCNN.pth\"\n",
    "state = {\n",
    "    'epoch': 9,\n",
    "    'state_dict': network.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "}\n",
    "torch.save(state, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on Single Subject\n",
    " Now that we have trained over the entire dataset, let us instead try to train over one subject, using the models we have determined before. This will help us decide if optimizing a model architecture over the entire training set also optimizes it for a single subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function\n",
    "To avoid copying the training loop over and over again, we make a training function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network,trainloader,valloader,testloader,y_test,original):\n",
    "    # Select loss criterion\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # create your optimizer\n",
    "    optimizer = optim.Adam(network.parameters(), lr=0.001)\n",
    "\n",
    "    # Setup learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "    # Train the network\n",
    "    num_epochs = 10\n",
    "\n",
    "    # Store the loss\n",
    "    stats = {\n",
    "        'train_accuracies': [],\n",
    "        'train_losses': [],\n",
    "        'val_accuracies': [],\n",
    "        'val_losses': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs): # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.float()\n",
    "            labels = labels.float()\n",
    "\n",
    "            # forward pass\n",
    "            outputs = network(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "\n",
    "            # backward + optimize\n",
    "            loss.backward() # backward to get gradient values\n",
    "\n",
    "            optimizer.step() # does the update\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # accumulate loss\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Make prediction for batch\n",
    "            _, predicted = outputs.max(1)\n",
    "\n",
    "            # Store accuracy for batch\n",
    "            # WE convert back from one-hot to integer for checking accuracy\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(torch.argmax(labels, dim=1)).sum().item()\n",
    "\n",
    "        # Store accuracy,loss for epoch\n",
    "        train_loss=running_loss/len(trainloader)\n",
    "        train_accuracy=100.*correct/total\n",
    "\n",
    "        # At the end of each epoch, calculate validation accuracy\n",
    "\n",
    "        # Set the network in eval mode since we're not training here\n",
    "        network.eval()\n",
    "\n",
    "         # Turn gradient computation off\n",
    "        with torch.no_grad():\n",
    "            val_accuracy, val_loss = validate(network, valloader, criterion)\n",
    "\n",
    "        # Set the network back in training mode\n",
    "        network.train()\n",
    "\n",
    "        stats['train_accuracies'].append(train_accuracy)\n",
    "        stats['train_losses'].append(train_loss)\n",
    "        stats['val_accuracies'].append(val_accuracy)\n",
    "        stats['val_losses'].append(val_loss)\n",
    "\n",
    "\n",
    "        # Display results\n",
    "        print(f'Epoch: {epoch}')\n",
    "        print(f'\\t -- Train Loss: {train_loss} | Train Accuracy: {train_accuracy}')\n",
    "        print(f'\\t -- Val Loss: {val_loss} | Val Accuracy: {val_accuracy}')\n",
    "\n",
    "        # At the end of each epoch, schedule the learning rate decay\n",
    "        scheduler.step()\n",
    "        \n",
    "    # Compute the result on the test set\n",
    "    network.eval()\n",
    "    outputs = None\n",
    "\n",
    "     # Turn gradient computation off\n",
    "    with torch.no_grad():\n",
    "        outputs = compute_test_outputs(network,testloader,y_test)\n",
    "\n",
    "    # Set the network back in training mode\n",
    "    network.train()\n",
    "\n",
    "    test_accuracy = test(outputs, original['y_test'])\n",
    "\n",
    "    num_examples = original['y_test'].size\n",
    "\n",
    "\n",
    "    print(f'Accuracy of the network on the {num_examples} test examples: {test_accuracy} %')\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data For Subject 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: torch.Size([195, 22, 250, 1])\n",
      "Valid data shape: torch.Size([47, 22, 250, 1])\n",
      "Test data shape: torch.Size([200, 22, 250, 1])\n",
      "Training target shape: torch.Size([195, 4])\n",
      "Valid target shape: torch.Size([47, 4])\n",
      "Test target shape: torch.Size([200, 4])\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test, original = getData(lib='torch', subject=[1])\n",
    "print('Training data shape: {}'.format(X_train.shape))\n",
    "print('Valid data shape: {}'.format(X_valid.shape))\n",
    "print('Test data shape: {}'.format(X_test.shape))\n",
    "\n",
    "print('Training target shape: {}'.format(y_train.shape))\n",
    "print('Valid target shape: {}'.format(y_valid.shape))\n",
    "print('Test target shape: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "trainset = torch.utils.data.TensorDataset(X_train,y_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "# Shuffle is set to false for validation and test sets since no training is done on them, all we do is evaluate.\n",
    "valset =  torch.utils.data.TensorDataset(X_valid, y_valid)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=0)\n",
    "\n",
    "testset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                          shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train BasicCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t -- Train Loss: 1.901903122663498 | Train Accuracy: 31.794871794871796\n",
      "\t -- Val Loss: 1.567372441291809 | Val Accuracy: 31.914893617021278\n",
      "Epoch: 1\n",
      "\t -- Train Loss: 1.532337635755539 | Train Accuracy: 61.02564102564103\n",
      "\t -- Val Loss: 2.1483118534088135 | Val Accuracy: 14.893617021276595\n",
      "Epoch: 2\n",
      "\t -- Train Loss: 0.8412402421236038 | Train Accuracy: 66.15384615384616\n",
      "\t -- Val Loss: 2.938992500305176 | Val Accuracy: 29.78723404255319\n",
      "Epoch: 3\n",
      "\t -- Train Loss: 0.9776134788990021 | Train Accuracy: 72.82051282051282\n",
      "\t -- Val Loss: 3.2597224712371826 | Val Accuracy: 31.914893617021278\n",
      "Epoch: 4\n",
      "\t -- Train Loss: 0.5207431279122829 | Train Accuracy: 80.51282051282051\n",
      "\t -- Val Loss: 4.28739070892334 | Val Accuracy: 38.297872340425535\n",
      "Epoch: 5\n",
      "\t -- Train Loss: 0.539712332203635 | Train Accuracy: 76.92307692307692\n",
      "\t -- Val Loss: 4.5871782302856445 | Val Accuracy: 29.78723404255319\n",
      "Epoch: 6\n",
      "\t -- Train Loss: 0.52094039414078 | Train Accuracy: 74.35897435897436\n",
      "\t -- Val Loss: 4.806315898895264 | Val Accuracy: 31.914893617021278\n",
      "Epoch: 7\n",
      "\t -- Train Loss: 0.3786505465977825 | Train Accuracy: 83.07692307692308\n",
      "\t -- Val Loss: 4.410066604614258 | Val Accuracy: 29.78723404255319\n",
      "Epoch: 8\n",
      "\t -- Train Loss: 0.2502058492973447 | Train Accuracy: 87.17948717948718\n",
      "\t -- Val Loss: 4.185645580291748 | Val Accuracy: 36.170212765957444\n",
      "Epoch: 9\n",
      "\t -- Train Loss: 0.6200382709503174 | Train Accuracy: 89.74358974358974\n",
      "\t -- Val Loss: 4.263232231140137 | Val Accuracy: 34.04255319148936\n",
      "Accuracy of the network on the 50 test examples: 4.514672686230249 %\n"
     ]
    }
   ],
   "source": [
    "network = BasicCNN()\n",
    "stats = train(network,trainloader,valloader,testloader,y_test,original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Optimized CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t -- Train Loss: 23.43313166499138 | Train Accuracy: 22.564102564102566\n",
      "\t -- Val Loss: 6.3031487464904785 | Val Accuracy: 21.27659574468085\n",
      "Epoch: 1\n",
      "\t -- Train Loss: 18.049654006958008 | Train Accuracy: 22.564102564102566\n",
      "\t -- Val Loss: 21.03857421875 | Val Accuracy: 27.659574468085108\n",
      "Epoch: 2\n",
      "\t -- Train Loss: 13.302429676055908 | Train Accuracy: 37.94871794871795\n",
      "\t -- Val Loss: 25.5417423248291 | Val Accuracy: 19.148936170212767\n",
      "Epoch: 3\n",
      "\t -- Train Loss: 8.560121655464172 | Train Accuracy: 42.56410256410256\n",
      "\t -- Val Loss: 17.6361141204834 | Val Accuracy: 25.53191489361702\n",
      "Epoch: 4\n",
      "\t -- Train Loss: 8.43664026260376 | Train Accuracy: 37.94871794871795\n",
      "\t -- Val Loss: 11.0520601272583 | Val Accuracy: 29.78723404255319\n",
      "Epoch: 5\n",
      "\t -- Train Loss: 10.637623906135559 | Train Accuracy: 43.58974358974359\n",
      "\t -- Val Loss: 8.588160514831543 | Val Accuracy: 25.53191489361702\n",
      "Epoch: 6\n",
      "\t -- Train Loss: 6.039632618427277 | Train Accuracy: 41.02564102564103\n",
      "\t -- Val Loss: 6.076840877532959 | Val Accuracy: 25.53191489361702\n",
      "Epoch: 7\n",
      "\t -- Train Loss: 4.246083058475051 | Train Accuracy: 44.61538461538461\n",
      "\t -- Val Loss: 4.412679672241211 | Val Accuracy: 31.914893617021278\n",
      "Epoch: 8\n",
      "\t -- Train Loss: 6.128786742687225 | Train Accuracy: 46.15384615384615\n",
      "\t -- Val Loss: 4.002019882202148 | Val Accuracy: 27.659574468085108\n",
      "Epoch: 9\n",
      "\t -- Train Loss: 5.262905061244965 | Train Accuracy: 54.35897435897436\n",
      "\t -- Val Loss: 4.742060661315918 | Val Accuracy: 27.659574468085108\n",
      "Accuracy of the network on the 50 test examples: 2.9345372460496613 %\n"
     ]
    }
   ],
   "source": [
    "network = OptimizedCNN()\n",
    "stats = train(network,trainloader,valloader,testloader,y_test,original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train OptimizedCNNV2 with aggressive dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t -- Train Loss: 2.169916808605194 | Train Accuracy: 24.102564102564102\n",
      "\t -- Val Loss: 1.5259003639221191 | Val Accuracy: 31.914893617021278\n",
      "Epoch: 1\n",
      "\t -- Train Loss: 2.154381275177002 | Train Accuracy: 46.666666666666664\n",
      "\t -- Val Loss: 1.60586678981781 | Val Accuracy: 25.53191489361702\n",
      "Epoch: 2\n",
      "\t -- Train Loss: 1.2756003141403198 | Train Accuracy: 53.333333333333336\n",
      "\t -- Val Loss: 2.452341318130493 | Val Accuracy: 31.914893617021278\n",
      "Epoch: 3\n",
      "\t -- Train Loss: 1.8245906829833984 | Train Accuracy: 56.41025641025641\n",
      "\t -- Val Loss: 2.5956027507781982 | Val Accuracy: 29.78723404255319\n",
      "Epoch: 4\n",
      "\t -- Train Loss: 1.6935427784919739 | Train Accuracy: 50.256410256410255\n",
      "\t -- Val Loss: 2.309718608856201 | Val Accuracy: 27.659574468085108\n",
      "Epoch: 5\n",
      "\t -- Train Loss: 1.7540714740753174 | Train Accuracy: 54.35897435897436\n",
      "\t -- Val Loss: 3.3111207485198975 | Val Accuracy: 29.78723404255319\n",
      "Epoch: 6\n",
      "\t -- Train Loss: 1.7529536187648773 | Train Accuracy: 52.82051282051282\n",
      "\t -- Val Loss: 3.9349160194396973 | Val Accuracy: 25.53191489361702\n",
      "Epoch: 7\n",
      "\t -- Train Loss: 1.2899350970983505 | Train Accuracy: 53.84615384615385\n",
      "\t -- Val Loss: 4.616067409515381 | Val Accuracy: 29.78723404255319\n",
      "Epoch: 8\n",
      "\t -- Train Loss: 1.4543809294700623 | Train Accuracy: 53.84615384615385\n",
      "\t -- Val Loss: 5.642443656921387 | Val Accuracy: 31.914893617021278\n",
      "Epoch: 9\n",
      "\t -- Train Loss: 1.1069491058588028 | Train Accuracy: 66.15384615384616\n",
      "\t -- Val Loss: 5.527837753295898 | Val Accuracy: 31.914893617021278\n",
      "Accuracy of the network on the 50 test examples: 3.3860045146726865 %\n"
     ]
    }
   ],
   "source": [
    "network = OptimizedCNNV2(dropout=0.6)\n",
    "stats = train(network,trainloader,valloader,testloader,y_test,original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train OptimizedCNNV2 with larger convolutional filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t -- Train Loss: 1.9180192351341248 | Train Accuracy: 30.256410256410255\n",
      "\t -- Val Loss: 1.6883116960525513 | Val Accuracy: 21.27659574468085\n",
      "Epoch: 1\n",
      "\t -- Train Loss: 2.5528873801231384 | Train Accuracy: 50.256410256410255\n",
      "\t -- Val Loss: 2.3009791374206543 | Val Accuracy: 19.148936170212767\n",
      "Epoch: 2\n",
      "\t -- Train Loss: 2.103111118078232 | Train Accuracy: 60.51282051282051\n",
      "\t -- Val Loss: 4.0171003341674805 | Val Accuracy: 17.02127659574468\n",
      "Epoch: 3\n",
      "\t -- Train Loss: 1.3703769650310278 | Train Accuracy: 57.43589743589744\n",
      "\t -- Val Loss: 5.223966598510742 | Val Accuracy: 25.53191489361702\n",
      "Epoch: 4\n",
      "\t -- Train Loss: 2.3081869184970856 | Train Accuracy: 51.282051282051285\n",
      "\t -- Val Loss: 4.2109856605529785 | Val Accuracy: 25.53191489361702\n",
      "Epoch: 5\n",
      "\t -- Train Loss: 1.0798646286129951 | Train Accuracy: 66.66666666666667\n",
      "\t -- Val Loss: 3.7970104217529297 | Val Accuracy: 34.04255319148936\n",
      "Epoch: 6\n",
      "\t -- Train Loss: 1.12257519364357 | Train Accuracy: 69.74358974358974\n",
      "\t -- Val Loss: 5.077014446258545 | Val Accuracy: 31.914893617021278\n",
      "Epoch: 7\n",
      "\t -- Train Loss: 1.0325349755585194 | Train Accuracy: 68.2051282051282\n",
      "\t -- Val Loss: 7.279452800750732 | Val Accuracy: 34.04255319148936\n",
      "Epoch: 8\n",
      "\t -- Train Loss: 0.7227676101028919 | Train Accuracy: 75.38461538461539\n",
      "\t -- Val Loss: 5.543062686920166 | Val Accuracy: 25.53191489361702\n",
      "Epoch: 9\n",
      "\t -- Train Loss: 0.7580567374825478 | Train Accuracy: 76.92307692307692\n",
      "\t -- Val Loss: 4.406835556030273 | Val Accuracy: 36.170212765957444\n",
      "Accuracy of the network on the 50 test examples: 4.740406320541761 %\n"
     ]
    }
   ],
   "source": [
    "network = OptimizedCNNV2(dropout=0.4, filter_size = (20,1))\n",
    "stats = train(network,trainloader,valloader,testloader,y_test,original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t -- Train Loss: 1.5814472138881683 | Train Accuracy: 22.05128205128205\n",
      "\t -- Val Loss: 1.4769355058670044 | Val Accuracy: 29.78723404255319\n",
      "Epoch: 1\n",
      "\t -- Train Loss: 1.177191972732544 | Train Accuracy: 49.23076923076923\n",
      "\t -- Val Loss: 1.9374945163726807 | Val Accuracy: 31.914893617021278\n",
      "Epoch: 2\n",
      "\t -- Train Loss: 1.2347363233566284 | Train Accuracy: 51.282051282051285\n",
      "\t -- Val Loss: 1.9495785236358643 | Val Accuracy: 31.914893617021278\n",
      "Epoch: 3\n",
      "\t -- Train Loss: 1.3504549264907837 | Train Accuracy: 53.333333333333336\n",
      "\t -- Val Loss: 1.6652377843856812 | Val Accuracy: 31.914893617021278\n",
      "Epoch: 4\n",
      "\t -- Train Loss: 1.0847207903862 | Train Accuracy: 54.87179487179487\n",
      "\t -- Val Loss: 1.8223068714141846 | Val Accuracy: 38.297872340425535\n",
      "Epoch: 5\n",
      "\t -- Train Loss: 1.0190753638744354 | Train Accuracy: 54.87179487179487\n",
      "\t -- Val Loss: 2.127650022506714 | Val Accuracy: 29.78723404255319\n",
      "Epoch: 6\n",
      "\t -- Train Loss: 1.248041808605194 | Train Accuracy: 58.46153846153846\n",
      "\t -- Val Loss: 1.9412500858306885 | Val Accuracy: 29.78723404255319\n",
      "Epoch: 7\n",
      "\t -- Train Loss: 0.9690820872783661 | Train Accuracy: 63.58974358974359\n",
      "\t -- Val Loss: 1.9070547819137573 | Val Accuracy: 34.04255319148936\n",
      "Epoch: 8\n",
      "\t -- Train Loss: 0.6843575574457645 | Train Accuracy: 68.2051282051282\n",
      "\t -- Val Loss: 1.8328969478607178 | Val Accuracy: 40.42553191489362\n",
      "Epoch: 9\n",
      "\t -- Train Loss: 1.1116978079080582 | Train Accuracy: 65.64102564102564\n",
      "\t -- Val Loss: 1.7672096490859985 | Val Accuracy: 36.170212765957444\n",
      "Accuracy of the network on the 50 test examples: 3.837471783295711 %\n"
     ]
    }
   ],
   "source": [
    "network = DeepCNN(dropout=0.4, filter_size = (5,1))\n",
    "stats = train(network,trainloader,valloader,testloader,y_test,original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VariableFiltersCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t -- Train Loss: 2.3057503700256348 | Train Accuracy: 29.23076923076923\n",
      "\t -- Val Loss: 1.689765453338623 | Val Accuracy: 27.659574468085108\n",
      "Epoch: 1\n",
      "\t -- Train Loss: 1.8557667136192322 | Train Accuracy: 63.07692307692308\n",
      "\t -- Val Loss: 4.286262035369873 | Val Accuracy: 29.78723404255319\n",
      "Epoch: 2\n",
      "\t -- Train Loss: 1.187065945006907 | Train Accuracy: 61.53846153846154\n",
      "\t -- Val Loss: 4.9824934005737305 | Val Accuracy: 29.78723404255319\n",
      "Epoch: 3\n",
      "\t -- Train Loss: 2.203248620033264 | Train Accuracy: 65.12820512820512\n",
      "\t -- Val Loss: 4.915523529052734 | Val Accuracy: 34.04255319148936\n",
      "Epoch: 4\n",
      "\t -- Train Loss: 1.1948320865631104 | Train Accuracy: 63.07692307692308\n",
      "\t -- Val Loss: 5.770066738128662 | Val Accuracy: 27.659574468085108\n",
      "Epoch: 5\n",
      "\t -- Train Loss: 1.5614760592579842 | Train Accuracy: 62.56410256410256\n",
      "\t -- Val Loss: 6.147514343261719 | Val Accuracy: 34.04255319148936\n",
      "Epoch: 6\n",
      "\t -- Train Loss: 1.265513613820076 | Train Accuracy: 78.97435897435898\n",
      "\t -- Val Loss: 6.115288257598877 | Val Accuracy: 38.297872340425535\n",
      "Epoch: 7\n",
      "\t -- Train Loss: 0.7578859180212021 | Train Accuracy: 78.46153846153847\n",
      "\t -- Val Loss: 6.1619133949279785 | Val Accuracy: 42.5531914893617\n",
      "Epoch: 8\n",
      "\t -- Train Loss: 0.5768828522413969 | Train Accuracy: 82.05128205128206\n",
      "\t -- Val Loss: 5.756494522094727 | Val Accuracy: 40.42553191489362\n",
      "Epoch: 9\n",
      "\t -- Train Loss: 0.7746042013168335 | Train Accuracy: 78.97435897435898\n",
      "\t -- Val Loss: 5.857848644256592 | Val Accuracy: 38.297872340425535\n",
      "Accuracy of the network on the 50 test examples: 4.288939051918736 %\n"
     ]
    }
   ],
   "source": [
    "network = VariableFiltersCNN(filters=[50,100,200,250])\n",
    "stats = train(network,trainloader,valloader,testloader,y_test,original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "These architectures perform very poorly when trained on only one subject's data. Determining an architecture by optimizing over the entire training set, does not produce an optimal architecture for training over one subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
